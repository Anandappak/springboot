code dependancy : -
<dependencies>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-aws</artifactId>
        <version>3.2.2</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-common</artifactId>
        <version>3.2.2</version>
    </dependency>
    <dependency>
        <groupId>org.apache.parquet</groupId>
        <artifactId>parquet-hadoop</artifactId>
        <version>1.11.1</version>
    </dependency>
    <dependency>
        <groupId>com.amazonaws</groupId>
        <artifactId>aws-java-sdk-bundle</artifactId>
        <version>1.11.969</version>
    </dependency>
</dependencies>

2)Configure Hadoop to connect to S3
import org.apache.hadoop.conf.Configuration;

public class S3Configuration {
    public static Configuration getHadoopConfiguration() {
        Configuration conf = new Configuration();
        conf.set("fs.s3a.access.key", "your-access-key");
        conf.set("fs.s3a.secret.key", "your-secret-key");
        conf.set("fs.s3a.endpoint", "s3.amazonaws.com");
        conf.set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem");
        return conf;
    }
}


import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.hadoop.ParquetFileReader;
import org.apache.parquet.hadoop.metadata.ParquetMetadata;
import org.apache.parquet.schema.MessageType;
import org.apache.parquet.tools.read.SimpleReadSupport;

import java.io.IOException;

public class ParquetReaderExample {
    public static void main(String[] args) {
        Configuration conf = S3Configuration.getHadoopConfiguration();
        Path parquetFilePath = new Path("s3a://your-bucket/your-parquet-file.parquet");

        try {
            ParquetMetadata readFooter = ParquetFileReader.readFooter(conf, parquetFilePath);
            MessageType schema = readFooter.getFileMetaData().getSchema();

            System.out.println("Parquet schema: " + schema);

            ParquetFileReader reader = ParquetFileReader.open(conf, parquetFilePath, new SimpleReadSupport());
            // Read and process the Parquet file content here
            reader.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
logic started

<dependencies>
    <dependency>
        <groupId>software.amazon.awssdk</groupId>
        <artifactId>s3</artifactId>
        <version>2.17.106</version>
    </dependency>
    <dependency>
        <groupId>org.apache.parquet</groupId>
        <artifactId>parquet-avro</artifactId>
        <version>1.12.2</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>3.3.1</version>
    </dependency>
</dependencies>

import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.GetObjectRequest;
import software.amazon.awssdk.services.s3.model.S3Object;

import java.nio.file.Paths;

public class S3ParquetReader {
    private static final Region REGION = Region.US_WEST_2;
    private static final String BUCKET_NAME = "your-bucket-name";
    private static final String KEY = "path/to/your-file.parquet";

    public static void main(String[] args) {
        S3Client s3 = S3Client.builder()
                .region(REGION)
                .credentialsProvider(ProfileCredentialsProvider.create())
                .build();

        GetObjectRequest getObjectRequest = GetObjectRequest.builder()
                .bucket(BUCKET_NAME)
                .key(KEY)
                .build();

        s3.getObject(getObjectRequest, Paths.get("/path/to/local/parquet-file.parquet"));
    }
}

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.hadoop.ParquetReader;
import org.apache.parquet.hadoop.metadata.CompressionCodecName;
import org.apache.parquet.hadoop.util.HadoopInputFile;
import org.apache.parquet.avro.AvroParquetReader;
import org.apache.avro.generic.GenericRecord;

import java.io.IOException;

public class ParquetFileReader {
    public static void main(String[] args) {
        Path parquetFilePath = new Path("/path/to/local/parquet-file.parquet");
        Configuration configuration = new Configuration();

        try (ParquetReader<GenericRecord> reader = AvroParquetReader.<GenericRecord>builder(HadoopInputFile.fromPath(parquetFilePath, configuration)).build()) {
            GenericRecord record;
            while ((record = reader.read()) != null) {
                System.out.println(record);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.GetObjectRequest;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.hadoop.ParquetReader;
import org.apache.parquet.avro.AvroParquetReader;
import org.apache.avro.generic.GenericRecord;
import java.nio.file.Paths;
import java.io.IOException;

public class S3ParquetReader {
    private static final Region REGION = Region.US_WEST_2;
    private static final String BUCKET_NAME = "your-bucket-name";
    private static final String KEY = "path/to/your-file.parquet";

    public static void main(String[] args) {
        // Step 1: Initialize AWS S3 Client
        S3Client s3 = S3Client.builder()
                .region(REGION)
                .credentialsProvider(ProfileCredentialsProvider.create())
                .build();

        // Step 2: Download Parquet file from S3 to local filesystem
        GetObjectRequest getObjectRequest = GetObjectRequest.builder()
                .bucket(BUCKET_NAME)
                .key(KEY)
                .build();
        s3.getObject(getObjectRequest, Paths.get("/path/to/local/parquet-file.parquet"));

        // Step 3: Read the Parquet file
        Path parquetFilePath = new Path("/path/to/local/parquet-file.parquet");
        Configuration configuration = new Configuration();

        try (ParquetReader<GenericRecord> reader = AvroParquetReader.<GenericRecord>builder(parquetFilePath).withConf(configuration).build()) {
            GenericRecord record;
            while ((record = reader.read()) != null) {
                System.out.println(record);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

